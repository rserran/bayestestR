<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Example 1: Initiation to Bayesian models • bayestestR</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Example 1: Initiation to Bayesian models">
<meta property="og:description" content="">
<meta property="og:image" content="/logo.png">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-97457476-7"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-97457476-7');
</script>
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">bayestestR</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.2.3</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li>
  <a href="../reference/index.html">Features</a>
</li>
<li>
  <a href="../articles/bayestestR.html">Get started</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/example1.html">1. Initiation to Bayesian models</a>
    </li>
    <li>
      <a href="../articles/example2.html">2. Confirmation of Bayesian skills</a>
    </li>
    <li>
      <a href="../articles/example3.html">3. Become a Bayesian master</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/credible_interval.html">Credible Intervals (CI)</a>
    </li>
    <li>
      <a href="../articles/region_of_practical_equivalence.html">Region of Practical Equivalence (ROPE)</a>
    </li>
    <li>
      <a href="../articles/probability_of_direction.html">Probability of Direction (pd)</a>
    </li>
    <li>
      <a href="../articles/bayes_factors.html">Bayes Factors (BF)</a>
    </li>
    <li>
      <a href="../articles/indicesEstimationComparison.html">Comparison of Point-Estimates</a>
    </li>
    <li>
      <a href="../articles/indicesExistenceComparison.html">Comparison of Indices of Effect Existence</a>
    </li>
  </ul>
</li>
<li>
  <a href="../articles/guidelines.html">Guidelines</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/easystats/bayestestR">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Example 1: Initiation to Bayesian models</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/easystats/bayestestR/blob/master/vignettes/example1.Rmd"><code>vignettes/example1.Rmd</code></a></small>
      <div class="hidden name"><code>example1.Rmd</code></div>

    </div>

    
    
<p>This vignette can be referred to by citing the package:</p>
<ul>
<li>Makowski, D., Ben-Shachar M. S. &amp; Lüdecke, D. (2019). <em>Understand and Describe Bayesian Models and Posterior Distributions using bayestestR</em>. Available from <a href="https://github.com/easystats/bayestestR" class="uri">https://github.com/easystats/bayestestR</a>. DOI: <a href="https://zenodo.org/record/2556486">10.5281/zenodo.2556486</a>.</li>
</ul>
<hr>
<p>Now that you’ve read the <a href="https://easystats.github.io/bayestestR/articles/bayestestR.html"><strong>Get started</strong></a> section, let’s dive in the <strong>subtleties of Bayesian modelling using R</strong>.</p>
<div id="loading-the-packages" class="section level2">
<h2 class="hasAnchor">
<a href="#loading-the-packages" class="anchor"></a>Loading the packages</h2>
<p>Once you’ve <a href="https://easystats.github.io/bayestestR/articles/bayestestR.html#bayestestr-installation">installed</a> the necessary packages, we can load <code>rstanarm</code> (to fit the models), <code>bayestestR</code> (to compute useful indices) and <code>insight</code> (to access the parameters).</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(rstanarm)</a>
<a class="sourceLine" id="cb1-2" title="2"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(bayestestR)</a>
<a class="sourceLine" id="cb1-3" title="3"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(insight)</a></code></pre></div>
</div>
<div id="simple-linear-model-aka-a-regression" class="section level2">
<h2 class="hasAnchor">
<a href="#simple-linear-model-aka-a-regression" class="anchor"></a>Simple linear model (<em>aka</em> a regression)</h2>
<p>We will begin by conducting a simple linear regression to test the relationship between <code>Petal.Length</code> (our predictor, or <em>independent</em>, variable) and <code>Sepal.Length</code> (our response, or <em>dependent</em>, variable) from the <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set"><code>iris</code></a> dataset which is included by default in R.</p>
<div id="fitting-the-model" class="section level3">
<h3 class="hasAnchor">
<a href="#fitting-the-model" class="anchor"></a>Fitting the model</h3>
<p>Let’s start by fitting the <strong>frequentist</strong> version of the model, just to have a reference point:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1">model &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/lm">lm</a></span>(Sepal.Length <span class="op">~</span><span class="st"> </span>Petal.Length, <span class="dt">data=</span>iris)</a>
<a class="sourceLine" id="cb2-2" title="2"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/summary">summary</a></span>(model)</a></code></pre></div>
<pre><code>&gt; 
&gt; Call:
&gt; lm(formula = Sepal.Length ~ Petal.Length, data = iris)
&gt; 
&gt; Residuals:
&gt;     Min      1Q  Median      3Q     Max 
&gt; -1.2468 -0.2966 -0.0152  0.2768  1.0027 
&gt; 
&gt; Coefficients:
&gt;              Estimate Std. Error t value Pr(&gt;|t|)    
&gt; (Intercept)    4.3066     0.0784    54.9   &lt;2e-16 ***
&gt; Petal.Length   0.4089     0.0189    21.6   &lt;2e-16 ***
&gt; ---
&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
&gt; 
&gt; Residual standard error: 0.41 on 148 degrees of freedom
&gt; Multiple R-squared:  0.76,    Adjusted R-squared:  0.758 
&gt; F-statistic:  469 on 1 and 148 DF,  p-value: &lt;2e-16</code></pre>
<p>In this model, the linear relationship between <code>Petal.Length</code> and <code>Sepal.Length</code> is <strong>positive and significant</strong> (beta = 0.41, <em>t</em>(148) = 21.6, <em>p</em> &lt; .001). This means that for each one-unit increase in <code>Petal.Length</code> (the predictor), you can expect <code>Sepal.Length</code> (the response) to increase by <strong>0.41</strong>. This effect can be visualized by plotting the predictor values on the <code>x</code> axis and the response values as <code>y</code> using the <code>ggplot2</code> package:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(ggplot2)  <span class="co"># Load the package</span></a>
<a class="sourceLine" id="cb4-2" title="2"></a>
<a class="sourceLine" id="cb4-3" title="3"><span class="co"># The ggplot function takes the data as argument, and then the variables </span></a>
<a class="sourceLine" id="cb4-4" title="4"><span class="co"># related to aesthetic features such as the x and y axes.</span></a>
<a class="sourceLine" id="cb4-5" title="5"><span class="kw">ggplot</span>(iris, <span class="kw">aes</span>(<span class="dt">x=</span>Petal.Length, <span class="dt">y=</span>Sepal.Length)) <span class="op">+</span></a>
<a class="sourceLine" id="cb4-6" title="6"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st">  </span><span class="co"># This adds the points</span></a>
<a class="sourceLine" id="cb4-7" title="7"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">"lm"</span>) <span class="co"># This adds a regression line</span></a></code></pre></div>
<p><img src="example1_files/figure-html/unnamed-chunk-4-1.png" width="700"></p>
<p>Now let’s fit a <strong>Bayesian version</strong> of the model by using the <code>stan_glm</code> function in the <code>rstanarm</code> package:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" title="1">model &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(Sepal.Length <span class="op">~</span><span class="st"> </span>Petal.Length, <span class="dt">data=</span>iris)</a></code></pre></div>
<p>You can see the sampling algorithm being run.</p>
</div>
<div id="extracting-the-posterior" class="section level3">
<h3 class="hasAnchor">
<a href="#extracting-the-posterior" class="anchor"></a>Extracting the posterior</h3>
<p>Once it is done, let us extract the parameters (<em>i.e.</em>, coefficients) of the model.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" title="1">posteriors &lt;-<span class="st"> </span>insight<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/insight/topics/get_parameters">get_parameters</a></span>(model)</a>
<a class="sourceLine" id="cb6-2" title="2"></a>
<a class="sourceLine" id="cb6-3" title="3"><span class="kw"><a href="https://www.rdocumentation.org/packages/utils/topics/head">head</a></span>(posteriors)  <span class="co"># Show the first 6 rows</span></a></code></pre></div>
<pre><code>&gt;   (Intercept) Petal.Length
&gt; 1         4.4         0.40
&gt; 2         4.5         0.37
&gt; 3         4.3         0.41
&gt; 4         4.4         0.40
&gt; 5         4.3         0.41
&gt; 6         4.3         0.42</code></pre>
<p>As we can see, the parameters take the form of a lengthy dataframe with two columns, corresponding to the <code>intercept</code> and the effect of <code>Petal.Length</code>. These columns contain the <strong>posterior distributions</strong> of these two parameters. In simple terms, the posterior distribution is a set of different plausible values for each parameter.</p>
<div id="about-posterior-draws" class="section level4">
<h4 class="hasAnchor">
<a href="#about-posterior-draws" class="anchor"></a>About posterior draws</h4>
<p>Let’s look at the length of the posteriors.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" title="1"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/nrow">nrow</a></span>(posteriors)  <span class="co"># Size (number of rows)</span></a></code></pre></div>
<pre><code>&gt; [1] 4000</code></pre>
<blockquote>
<p><strong>Why is the size 4000, and not more or less?</strong></p>
</blockquote>
<p>First of all, these observations (the rows) are usually referred to as <strong>posterior draws</strong>. The underlying idea is that the Bayesian sampling algorithm (<em>e.g.</em>, <strong>Monte Carlo Markov Chains - MCMC</strong>) will <em>draw</em> from the hidden true posterior distribution. Thus, it is through these posterior draws that we can estimate the underlying true posterior distribution. <strong>Therefore, the more draws you have, the better your estimation of the posterior distribution</strong>. However, increased draws also means longer computation time.</p>
<p>If we look at the documentation (<code>?sampling</code>) for the rstanarm <code>"sampling"</code> algorithm used by default in the model above, we can see several parameters that influence the number of posterior draws. By default, there are <strong>4</strong> <code>chains</code> (you can see it as distinct sampling runs), that each create <strong>2000</strong> <code>iter</code> (draws). However, only half of these iterations are kept, as half are used for <code>warm-up</code> (the convergence of the algorithm). Thus, the total is <strong><code>4 chains * (2000 iterations - 1000 warm-up) = 4000</code></strong> posterior draws. We can change that, for instance:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" title="1">model &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(Sepal.Length <span class="op">~</span><span class="st"> </span>Petal.Length, <span class="dt">data=</span>iris, <span class="dt">chains =</span> <span class="dv">2</span>, <span class="dt">iter =</span> <span class="dv">1000</span>, <span class="dt">warmup =</span> <span class="dv">250</span>)</a>
<a class="sourceLine" id="cb10-2" title="2"> </a>
<a class="sourceLine" id="cb10-3" title="3"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/nrow">nrow</a></span>(insight<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/insight/topics/get_parameters">get_parameters</a></span>(model))  <span class="co"># Size (number of rows)</span></a></code></pre></div>
<pre><code>[1] 1500</code></pre>
<p>In this case, as would be expected, we have <strong><code>2 chains * (1000 iterations - 250 warm-up) = 1500</code></strong> posterior draws. However, let’s keep our first model with the default setup.</p>
</div>
<div id="visualizing-the-posterior-distribution" class="section level4">
<h4 class="hasAnchor">
<a href="#visualizing-the-posterior-distribution" class="anchor"></a>Visualizing the posterior distribution</h4>
<p>Now that we’ve understood where these values come from, let’s look at them. We will start by visualizing the posterior distribution of our parameter of interest, the effect of <code>Petal.Length</code>.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" title="1"><span class="kw">ggplot</span>(posteriors, <span class="kw">aes</span>(<span class="dt">x =</span> Petal.Length)) <span class="op">+</span></a>
<a class="sourceLine" id="cb12-2" title="2"><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">fill =</span> <span class="st">"orange"</span>)</a></code></pre></div>
<p><img src="example1_files/figure-html/unnamed-chunk-12-1.png" width="700"></p>
<p>This distribution represents the <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability</a> (the y axis) of different effects (the x axis). The central values are more probable than the extreme values. As you can see, this distribution ranges from about <strong>0.35 to 0.50</strong>, with the bulk of it being at around <strong>0.41</strong>.</p>
<blockquote>
<p><strong>Congrats! You’ve just described your posterior distribution.</strong></p>
</blockquote>
<p>And this is at the heart of Bayesian analysis. We don’t need <em>p</em>-values, <em>t</em>-values or degrees of freedom: <strong>everything is there</strong>, within this posterior distribution.</p>
<p>Our description above is consistent with the values obtained from the frequentist regression (which resulted in a beta of <strong>0.41</strong>). This is reassuring! Indeed, <strong>in most cases a Bayesian analysis does not drastically change the results</strong> or their interpretation. Rather, it makes the results more interpretable and intuitive, and eaasier to understand and describe.</p>
<p>We can now go ahead and <strong>precisely characterize</strong> this posterior distribution.</p>
</div>
</div>
<div id="describing-the-posterior" class="section level3">
<h3 class="hasAnchor">
<a href="#describing-the-posterior" class="anchor"></a>Describing the Posterior</h3>
<p>Unfortunately, it is often not practical to report the whole posterior distributions as graphs. We need to find a <strong>concise way to summarize it</strong>. We recommend to describe the posterior distribution with <strong>3 elements</strong>:</p>
<ol style="list-style-type: decimal">
<li>A <strong>point-estimate</strong> which is a one-value summary (similar to the <em>beta</em> in frequentist regressions).</li>
<li>A <strong>credible interval</strong> representing the associated uncertainty.</li>
<li>Some <strong>indices of significance</strong>, giving information about the relative importance of this effect.</li>
</ol>
<div id="point-estimate" class="section level4">
<h4 class="hasAnchor">
<a href="#point-estimate" class="anchor"></a>Point-estimate</h4>
<p><strong>What single value can best represent my posterior distribution?</strong></p>
<p>Centrality indices, such as the <em>mean</em>, the <em>median</em> or the <em>mode</em> are usually used as point-estimates - but what’s the difference between them? Let’s answer this by first inspecting the <strong>mean</strong>:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" title="1"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/mean">mean</a></span>(posteriors<span class="op">$</span>Petal.Length)</a></code></pre></div>
<pre><code>&gt; [1] 0.41</code></pre>
<p>This is close to the frequentist beta. But as we know, the mean is quite sensitive to outliers or extremes values. Maybe the <strong>median</strong> could be more robust?</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" title="1"><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/median">median</a></span>(posteriors<span class="op">$</span>Petal.Length)</a></code></pre></div>
<pre><code>&gt; [1] 0.41</code></pre>
<p>Well, this is <strong>very close to the mean</strong> (and identical when rounding the values). Maybe we could take the <strong>mode</strong>, that is, the <em>peak</em> of the posterior distribution? In the Bayesian framework, this value is called the <strong>Maximum A Posteriori (MAP)</strong>. Let’s see:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" title="1"><span class="kw"><a href="../reference/map_estimate.html">map_estimate</a></span>(posteriors<span class="op">$</span>Petal.Length)</a></code></pre></div>
<pre><code>&gt; MAP = 0.41</code></pre>
<p><strong>They are all very close!</strong> Let’s visualize these values on the posterior distribution:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" title="1"><span class="kw">ggplot</span>(posteriors, <span class="kw">aes</span>(<span class="dt">x =</span> Petal.Length)) <span class="op">+</span></a>
<a class="sourceLine" id="cb19-2" title="2"><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">fill =</span> <span class="st">"orange"</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb19-3" title="3"><span class="st">  </span><span class="co"># The mean in blue</span></a>
<a class="sourceLine" id="cb19-4" title="4"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/mean">mean</a></span>(posteriors<span class="op">$</span>Petal.Length), <span class="dt">color=</span><span class="st">"blue"</span>, <span class="dt">size=</span><span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb19-5" title="5"><span class="st">  </span><span class="co"># The median in red</span></a>
<a class="sourceLine" id="cb19-6" title="6"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/median">median</a></span>(posteriors<span class="op">$</span>Petal.Length), <span class="dt">color=</span><span class="st">"red"</span>, <span class="dt">size=</span><span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb19-7" title="7"><span class="st">  </span><span class="co"># The MAP in purple</span></a>
<a class="sourceLine" id="cb19-8" title="8"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept=</span><span class="kw"><a href="../reference/map_estimate.html">map_estimate</a></span>(posteriors<span class="op">$</span>Petal.Length), <span class="dt">color=</span><span class="st">"purple"</span>, <span class="dt">size=</span><span class="dv">1</span>)</a></code></pre></div>
<p><img src="example1_files/figure-html/unnamed-chunk-16-1.png" width="700"></p>
<p>Well, all these values give very similar results. Thus, <strong>we will choose the median</strong>, as this value has a direct meaning from a probabilistic perspective: <strong>there is 50% chance that the true effect is higher and 50% chance that the effect is lower</strong> (as it divides the distribution in two equal parts).</p>
</div>
<div id="uncertainty" class="section level4">
<h4 class="hasAnchor">
<a href="#uncertainty" class="anchor"></a>Uncertainty</h4>
<p>Now that the have a point-estimate, we have to <strong>describe the uncertainty</strong>. We could compute the range:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" title="1"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/range">range</a></span>(posteriors<span class="op">$</span>Petal.Length)</a></code></pre></div>
<pre><code>&gt; [1] 0.35 0.48</code></pre>
<p>But does it make sense to include all these extreme values? Probably not. Thus, we will compute a <a href="https://easystats.github.io/bayestestR/articles/credible_interval.html"><strong>credible interval</strong></a>. Long story short, it’s kind of similar to a frequentist <strong>confidence interval</strong>, but easier to interpret and easier to compute — <em>and it makes more sense</em>.</p>
<p>We will compute this <strong>credible interval</strong> based on the <a href="https://easystats.github.io/bayestestR/articles/credible_interval.html#different-types-of-cis">Highest Density Interval (HDI)</a>. It will give us the range containing the 89% most probable effect values. <strong>Note that we will use 89% CIs instead of 95%</strong> CIs (as in the frequentist framework), as the 89% level gives more <a href="https://easystats.github.io/bayestestR/articles/credible_interval.html#why-is-the-default-89">stable results</a> <span class="citation">(Kruschke 2014)</span> and reminds us about the arbitrarity of such conventions <span class="citation">(McElreath 2018)</span>.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" title="1"><span class="kw"><a href="../reference/hdi.html">hdi</a></span>(posteriors<span class="op">$</span>Petal.Length, <span class="dt">ci=</span><span class="fl">0.89</span>)</a></code></pre></div>
<pre><code>&gt; # Highest Density Interval
&gt; 
&gt;       89% HDI
&gt;  [0.38, 0.44]</code></pre>
<p>Nice, so we can conclude that <strong>the effect has 89% chance of falling within the <code>[0.38, 0.44]</code> range</strong>. We have just computed the two most important pieces of information for describing our effects.</p>
</div>
<div id="effect-significance" class="section level4">
<h4 class="hasAnchor">
<a href="#effect-significance" class="anchor"></a>Effect significance</h4>
<p>However, in many scientific fields it not sufficient to simply describe the effects. Scientists also want to know if this effect has significance in practical or statistical terms, or in other words, whether the effect is important. For instnace, is the effect different from 0? So how do we <strong>assess the <em>significance</em> of an effect</strong>. How can we do this?</p>
<p>Well, in this particular case, it is very eloquent: <strong>all possible effect values (<em>i.e.</em>, the whole posterior distribution) are positive and over 0.35, which is already substantial evidence the effect is not zero</strong>.</p>
<p>But still, we want some objective decision criterion, to say if <strong>yes or no the effect is ‘significant’</strong>. One approach, similar to the frequentist framework, would be to see if the <strong>Credible Interval</strong> contains 0. If it is not the case, that would mean that our <strong>effect is ‘significant’</strong>.</p>
<p>But this index is not very fine-grained, isn’t it? <strong>Can we do better? Yes.</strong></p>
</div>
</div>
</div>
<div id="a-linear-model-with-a-categorical-predictor" class="section level2">
<h2 class="hasAnchor">
<a href="#a-linear-model-with-a-categorical-predictor" class="anchor"></a>A linear model with a categorical predictor</h2>
<p>Imagine for a moment you are interested in how the weight of chickens varies depending on two different <strong>feed types</strong>. For this exampe, we will start by selecting from the <code>chickwts</code> dataset (available in base R) two feed types of interest for us (<em>we do have peculiar interests</em>): <strong>meat meals</strong> and <strong>sunflowers</strong>.</p>
<div id="data-preparation-and-model-fitting" class="section level3">
<h3 class="hasAnchor">
<a href="#data-preparation-and-model-fitting" class="anchor"></a>Data preparation and model fitting</h3>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" title="1"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(dplyr)</a>
<a class="sourceLine" id="cb24-2" title="2"></a>
<a class="sourceLine" id="cb24-3" title="3"><span class="co"># We keep only rows for which feed is meatmeal or sunflower</span></a>
<a class="sourceLine" id="cb24-4" title="4">data &lt;-<span class="st"> </span>chickwts <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb24-5" title="5"><span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/filter">filter</a></span>(feed <span class="op">%in%</span><span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">"meatmeal"</span>, <span class="st">"sunflower"</span>))</a></code></pre></div>
<p>Let’s run another Bayesian regression to predict the <strong>weight</strong> with the <strong>two types of feed type</strong>.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" title="1">model &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(weight <span class="op">~</span><span class="st"> </span>feed, <span class="dt">data=</span>data)</a></code></pre></div>
</div>
<div id="posterior-description" class="section level3">
<h3 class="hasAnchor">
<a href="#posterior-description" class="anchor"></a>Posterior description</h3>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" title="1">posteriors &lt;-<span class="st"> </span>insight<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/insight/topics/get_parameters">get_parameters</a></span>(model)</a>
<a class="sourceLine" id="cb26-2" title="2"></a>
<a class="sourceLine" id="cb26-3" title="3"><span class="kw">ggplot</span>(posteriors, <span class="kw">aes</span>(<span class="dt">x=</span>feedsunflower)) <span class="op">+</span></a>
<a class="sourceLine" id="cb26-4" title="4"><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">fill =</span> <span class="st">"red"</span>)</a></code></pre></div>
<p><img src="example1_files/figure-html/unnamed-chunk-22-1.png" width="700"></p>
<p>This represents the <strong>posterior distribution of the difference between <code>meatmeal</code> and <code>sunflowers</code></strong>. Seems that the difference is rather <strong>positive</strong> (the values seems concentrated on the right side of 0)… Eating sunflowers makes you more fat (<em>at least, if you’re a chicken</em>). But, <strong>by how much?</strong> Let us compute the <strong>median</strong> and the <strong>CI</strong>:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" title="1"><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/median">median</a></span>(posteriors<span class="op">$</span>feedsunflower)</a></code></pre></div>
<pre><code>&gt; [1] 51</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" title="1"><span class="kw"><a href="../reference/hdi.html">hdi</a></span>(posteriors<span class="op">$</span>feedsunflower)</a></code></pre></div>
<pre><code>&gt; # Highest Density Interval
&gt; 
&gt;        89% HDI
&gt;  [7.77, 87.66]</code></pre>
<p>It makes you fat by around <code>51</code> grams (the median). However, the uncertainty is quite high: <strong>there is 89% chance that the difference between the two feed types is between <code>7.77</code> and <code>87.66</code>.</strong></p>
<blockquote>
<p><strong>Is this effect different from 0?</strong></p>
</blockquote>
</div>
<div id="rope-percentage" class="section level3">
<h3 class="hasAnchor">
<a href="#rope-percentage" class="anchor"></a>ROPE Percentage</h3>
<p>Testing whether this distribution is different from 0 doesn’t make sense, as 0 is a single value (<em>and the probability that any distribution is different from a single value is infinite</em>).</p>
<p>However, one way to assess <strong>significance</strong> could be to define an area around 0, which will consider as <em>practically equivalent</em> to zero (<em>i.e.</em>, absence of, or negligible, effect). This is called the <a href="https://easystats.github.io/bayestestR/articles/region_of_practical_equivalence.html"><strong>Region of Practical Equivalence (ROPE)</strong></a>, and is one way of testing the significance of parameters.</p>
<p><strong>How can we define this region?</strong></p>
<blockquote>
<p><strong><em>Driing driiiing</em></strong></p>
</blockquote>
<p>– <strong><em>The easystats team speaking. How can we help?</em></strong></p>
<p>– <strong><em>I am Prof. Sanders. An expert in chicks… I mean chickens. Just calling to let you know that based on my expert knowledge, an effect between -20 and 20 is negligible. Bye.</em></strong></p>
<p>Well, that’s convenient. Now we know that we can define the ROPE as the <code>[-20, 20]</code> range. All effects within this range are considered as <em>null</em> (negligible). We can now compute the <strong>proportion of the 89% most probable values (the 89% CI) which are not null</strong>, <em>i.e.</em>, which are outside this range.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" title="1"><span class="kw"><a href="../reference/rope.html">rope</a></span>(posteriors<span class="op">$</span>feedsunflower, <span class="dt">range =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="op">-</span><span class="dv">20</span>, <span class="dv">20</span>), <span class="dt">ci=</span><span class="fl">0.89</span>)</a></code></pre></div>
<pre><code>&gt; # Proportion of samples inside the ROPE [-20.00, 20.00]:
&gt; 
&gt;  inside ROPE
&gt;       7.75 %</code></pre>
<p><strong>7.75% of the 89% CI can be considered as null</strong>. Is that a lot? Based on our <a href="https://easystats.github.io/bayestestR/articles/guidelines.html"><strong>guidelines</strong></a>, yes, it is too much. <strong>Based on this particular definition of ROPE</strong>, we conclude that this effect is not significant (the probability of being negligible is too high).</p>
<p>Although, to be honest, I have <strong>some doubts about this Prof. Sanders</strong>. I don’t really trust <strong>his definition of ROPE</strong>. Is there a more <strong>objective</strong> way of defining it?</p>
<div class="figure" style="text-align: center">
<img src="https://github.com/easystats/easystats/raw/master/man/figures/bayestestR/profsanders.png" alt="Prof. Sanders giving default values to define the Region of Practical Equivalence (ROPE)." width="75%"><p class="caption">
Prof. Sanders giving default values to define the Region of Practical Equivalence (ROPE).
</p>
</div>
<p><strong>Yes.</strong> One of the practice is for instance to use the <strong>tenth (<code>1/10 = 0.1</code>) of the standard deviation (SD)</strong> of the response variable, which can be considered as a “negligible” effect size <span class="citation">(Cohen 1988)</span>.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" title="1">rope_value &lt;-<span class="st"> </span><span class="fl">0.1</span> <span class="op">*</span><span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/sd">sd</a></span>(data<span class="op">$</span>weight)</a>
<a class="sourceLine" id="cb33-2" title="2">rope_range &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="op">-</span>rope_value, rope_value)</a>
<a class="sourceLine" id="cb33-3" title="3">rope_range</a></code></pre></div>
<pre><code>&gt; [1] -6.2  6.2</code></pre>
<p>Let’s redefine our ROPE as the region within the <code>[-6.2, 6.2]</code> range. <strong>Note that this can be directly obtained by the <code>rope_range</code> function :)</strong></p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" title="1">rope_value &lt;-<span class="st"> </span><span class="kw"><a href="../reference/rope_range.html">rope_range</a></span>(model)</a>
<a class="sourceLine" id="cb35-2" title="2">rope_range</a></code></pre></div>
<pre><code>&gt; [1] -6.2  6.2</code></pre>
<p>Let’s recompute the <strong>percentage in ROPE</strong>:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" title="1"><span class="kw"><a href="../reference/rope.html">rope</a></span>(posteriors<span class="op">$</span>feedsunflower, <span class="dt">range =</span> rope_range, <span class="dt">ci=</span><span class="fl">0.89</span>)</a></code></pre></div>
<pre><code>&gt; # Proportion of samples inside the ROPE [-6.17, 6.17]:
&gt; 
&gt;  inside ROPE
&gt;       0.00 %</code></pre>
<p>With this reasonable definition of ROPE, we observe that the 89% of the posterior distribution of the effect does <strong>not</strong> overlap with the ROPE. Thus, we can conclude that <strong>the effect is significant</strong> (in the sense of <em>important</em> enough to be noted).</p>
</div>
<div id="probability-of-direction-pd" class="section level3">
<h3 class="hasAnchor">
<a href="#probability-of-direction-pd" class="anchor"></a>Probability of Direction (pd)</h3>
<p>Maybe we are not interested in whether the effect is non-negligible. Maybe <strong>we just want to know if this effect is positive or negative</strong>. In this case, we can simply compute the proportion of the posterior that is positive, no matter the “size” of the effect.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb39-1" title="1">n_positive &lt;-<span class="st"> </span>posteriors <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb39-2" title="2"><span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/filter">filter</a></span>(feedsunflower <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># select only positive values</span></a>
<a class="sourceLine" id="cb39-3" title="3"><span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/nrow">nrow</a></span>() <span class="co"># Get length</span></a>
<a class="sourceLine" id="cb39-4" title="4">n_positive <span class="op">/</span><span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/nrow">nrow</a></span>(posteriors) <span class="op">*</span><span class="st"> </span><span class="dv">100</span></a></code></pre></div>
<pre><code>&gt; [1] "97.82"</code></pre>
<p>We can conclude that <strong>the effect is positive with a probability of 97.82%</strong>. We call this index the <a href="https://easystats.github.io/bayestestR/articles/probability_of_direction.html"><strong>Probability of Direction (pd)</strong></a>. It can, in fact, be computed more easily with the following:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb41-1" title="1"><span class="kw"><a href="../reference/p_direction.html">p_direction</a></span>(posteriors<span class="op">$</span>feedsunflower)</a></code></pre></div>
<pre><code>&gt; # Probability of Direction (pd)
&gt; 
&gt; pd = 97.82%</code></pre>
<p>Interestingly, it so happens that <strong>this index is usually highly correlated with the frequentist <em>p</em>-value</strong>. We could almost roughly infer the corresponding <em>p</em>-value with a simple transformation:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" title="1">pd &lt;-<span class="st"> </span><span class="fl">97.82</span></a>
<a class="sourceLine" id="cb43-2" title="2">onesided_p &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>pd <span class="op">/</span><span class="st"> </span><span class="dv">100</span>  </a>
<a class="sourceLine" id="cb43-3" title="3">twosided_p &lt;-<span class="st"> </span>onesided_p <span class="op">*</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb43-4" title="4">twosided_p</a></code></pre></div>
<pre><code>&gt; [1] 0.044</code></pre>
<p>If we ran our model in the frequentist framework, we should approximately observe an effect with a <em>p</em>-value of 0.04. <strong>Is that true?</strong></p>
<div id="comparison-to-frequentist" class="section level4">
<h4 class="hasAnchor">
<a href="#comparison-to-frequentist" class="anchor"></a>Comparison to frequentist</h4>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" title="1"><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/lm">lm</a></span>(weight <span class="op">~</span><span class="st"> </span>feed, <span class="dt">data=</span>data) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb45-2" title="2"><span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/summary">summary</a></span>()</a></code></pre></div>
<pre><code>&gt; 
&gt; Call:
&gt; lm(formula = weight ~ feed, data = data)
&gt; 
&gt; Residuals:
&gt;     Min      1Q  Median      3Q     Max 
&gt; -123.91  -25.91   -6.92   32.09  103.09 
&gt; 
&gt; Coefficients:
&gt;               Estimate Std. Error t value Pr(&gt;|t|)    
&gt; (Intercept)      276.9       17.2   16.10  2.7e-13 ***
&gt; feedsunflower     52.0       23.8    2.18     0.04 *  
&gt; ---
&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
&gt; 
&gt; Residual standard error: 57 on 21 degrees of freedom
&gt; Multiple R-squared:  0.185,   Adjusted R-squared:  0.146 
&gt; F-statistic: 4.77 on 1 and 21 DF,  p-value: 0.0405</code></pre>
<p>The frequentist model tells us that the difference is <strong>positive and significant</strong> (beta = 52, p = 0.04).</p>
<p><strong>Although we arrived to a similar conclusion, the Bayesian framework allowed us to develop a more profound and intuitive understanding of our effect, and of the uncertainty of its estimation.</strong></p>
</div>
</div>
</div>
<div id="all-with-one-function" class="section level2">
<h2 class="hasAnchor">
<a href="#all-with-one-function" class="anchor"></a>All with one function</h2>
<p>And yet, I agree, it was a bit <strong>tedious</strong> to extract and compute all the indices. <strong>But what if I told you that we can do all of this, and more, with only one function?</strong></p>
<blockquote>
<p><strong>Behold, <code>describe_posterior</code>!</strong></p>
</blockquote>
<p>This function computes all of the adored mentioned indices, and can be run directly on the model:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" title="1"><span class="kw"><a href="../reference/describe_posterior.html">describe_posterior</a></span>(model, <span class="dt">test =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">"p_direction"</span>,<span class="st">"rope"</span>,<span class="st">"bayesfactor"</span>))</a></code></pre></div>
<pre><code>&gt;       Parameter Median CI CI_low CI_high   pd ROPE_CI ROPE_low ROPE_high
&gt; 1   (Intercept)    277 89  250.2     307 1.00      89     -6.2       6.2
&gt; 2 feedsunflower     51 89    7.8      88 0.98      89     -6.2       6.2
&gt;   ROPE_Percentage      BF  ESS Rhat Prior_Distribution Prior_Location
&gt; 1               0 8.8e+11 3437    1             normal              0
&gt; 2               0 1.4e+00 3316    1             normal              0
&gt;   Prior_Scale
&gt; 1         617
&gt; 2         154</code></pre>
<p><strong>Tada!</strong> There we have it! The <strong>median</strong>, the <strong>CI</strong>, the <strong>pd</strong> and the <strong>ROPE percentage</strong>!</p>
<p>Understanding and describing posterior distributions is just one aspect of Bayesian modelling… <strong>Are you ready for more?</strong> <a href="https://easystats.github.io/bayestestR/articles/example2_GLM.html"><strong>Click here</strong></a> to see the next example.</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<div id="refs" class="references">
<div id="ref-cohen1988statistical">
<p>Cohen, Jacob. 1988. “Statistical Power Analysis for the Social Sciences.”</p>
</div>
<div id="ref-kruschke2014doing">
<p>Kruschke, John. 2014. <em>Doing Bayesian Data Analysis: A Tutorial with R, Jags, and Stan</em>. Academic Press.</p>
</div>
<div id="ref-mcelreath2018statistical">
<p>McElreath, Richard. 2018. <em>Statistical Rethinking: A Bayesian Course with Examples in R and Stan</em>. Chapman; Hall/CRC.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#loading-the-packages">Loading the packages</a></li>
      <li><a href="#simple-linear-model-aka-a-regression">Simple linear model (<em>aka</em> a regression)</a></li>
      <li><a href="#a-linear-model-with-a-categorical-predictor">A linear model with a categorical predictor</a></li>
      <li><a href="#all-with-one-function">All with one function</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by <a href="https://dominiquemakowski.github.io/">Dominique Makowski</a>, <a href="https://github.com/strengejacke">Daniel Lüdecke</a>, <a href="https://github.com/mattansb">Mattan S. Ben-Shachar</a>, <a href="http://www.humanfactors.io">Michael D. Wilson</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>
